# 効果検証入門メモ

サンプルコード
https://github.com/ghmagazine/cibook/

# 効果検証入門

読了 
因果推論の基本的な手法とそのアイデア、適用できる状況について大まかに知ることができた。
Rでの事例紹介、実際の検証を終えるのは良かった。
実際に使うとなると、仮定を満たすか、適切な実験設計ができるかなど研究に近いことができないといけないなと感じた。


## 気になるところ

- クラスター標準誤差の例
- 効果の内容をより細分化したい時どうするか
- 複数に介入がある場合の分析方法はあるのか
- nonparametric RDDで限定する範囲をデータに適用する場合、範囲をどうやって決めるか


## 1章：セレクションバイアスとRCT

<details>
<summary>memo</summary>

- 効果：施策（介入、処置）以外の要因が同一となった状況での比較によって知り得た施策の影響度合い
- RCT(ABテスト含む)：グループの平均的な性質が同質なグループを介入の有無で分け、これらに施策が与えた影響を比較する試験
- 母集団：潜在的に観測し得る全てのデータを含む集団。
- 標本集団：母集団からいくらかの標本を抽出してなる集団
- 推定：標本集団から母集団の性質を推測すること

#### ポテンシャルアウトカムフレームワーク
ユーザーを<img src="https://latex.codecogs.com/gif.latex?i" />、介入の有無を01とし、<img src="https://latex.codecogs.com/gif.latex?Z_{i}" />で表す。つまりはユーザー1に介入する場合<img src="https://latex.codecogs.com/gif.latex?Z_{i}=1" />。
このユーザの売り上げを<img src="https://latex.codecogs.com/gif.latex?Y_{i}" />で表す。つまりはユーザー1に介入があった場合、<img src="https://latex.codecogs.com/gif.latex?Y_{i}^{(1)}(Z_{i}=1)" />。
これは介入の有無でとる値が二値なので以下のように一つの式に整理できる。

<img src="https://latex.codecogs.com/gif.latex?Y_{i}&space;=&space;Y_{i}^{(0)}(1-Z_{i})&space;&plus;&space;Y_{i}^{(1)}Z_{i}" />

<br>
<br>

この単一のサンプル$i$に介入が行われた場合の売り上げと行われなかった場合の売り上げの差に介入の本当の効果があると考えることをポテンシャルアウトカムフレームワークという。ポテンシャルアウトカムとはつまりは反実仮想のことをさす。AとBの選択肢があるとき、私はAを選択してなんらかの結果を得た。この時のポテンシャルアウトカムはBを選択した時の結果のことをさす。売り上げならば介入した時の結果が<img src="https://latex.codecogs.com/gif.latex?Y_{i}^{(1)}" />ならば、ポテンシャルアウトカムは<img src="https://latex.codecogs.com/gif.latex?Y_{i}^{(0)}" />である。

介入の効果を表す値を<img src="https://latex.codecogs.com/gif.latex?\tau" />とすると、ユーザーiへの効果の度合いを売り上げの差分の形で表せる


<img src="https://latex.codecogs.com/gif.latex?\tau_{i} = Y_{i}^{(1)} - Y_{i}^{(0)}" />

<br>
<br>



しかし実際にはこの計算式のどちらか一方の結果（売り上げ）しか常に手に入れられない。分かるのはユーザー<img src="https://latex.codecogs.com/gif.latex?i" />への介入の有無とその結果のみであって、ポテンシャルアウトカムは得られない。つまりはある個人に関する比較はできないことになる。

そこで、次に考えるのはユーザーのグループである。介入の有無でグループを作り、これらを比較することで「平均的な」効果を測る。
これは売り上げの期待値を比較し、差を得ることである。

<img src="https://latex.codecogs.com/gif.latex?\tau = E[Y_{(1)}] - E[Y_{(0)}]" />

<br>
<br>

E[]は期待値を表し、母集団における平均を表している。つまりは興味のある介入の効果とは、母集団に置いて介入の有無ぞれぞれの場合の売り上げの平均の差である。このような効果は母集団の平均的な効果を示し、平均処置効果（Average treatment Effect: ATE）と呼ばれる。

上記式を変形すると、介入がなかった場合の売り上げに平均処置効果の補正項を加えることで介入があった場合の売り上げを求める式に改変できる。

<img src="https://latex.codecogs.com/gif.latex?E[Y_{(1)}]  =  E[Y_{(0)}] + \tau" />

<br>
<br>


#### 平均的な効果の比較
実験をせず（ランダム化せず）に担当者が選んだユーザーグループに介入の有無を割り振る場合、最も簡単な効果の推定はk区グループのユーザー売り上げの平均を差分をとることである。ここでの効果の推定値を$\hat{\tau}_{naive}$と表す。分析するデータのサンプルサイズをNとすると、


<img src="https://latex.codecogs.com/gif.latex?\hat{\tau}_{naive} = \frac{1}{\sum_{i=1}^{N}Z_{i}} \sum_{i=1}^{N}Y_{i}Z_{i} - \frac{1}{1- \sum_{i=1}^{N}Z_{i}} \sum_{i=1}^{N}Y_{i}(1- Z_{i})" />

<br>
<br>

実際には100の効果しかないデータで300の効果があるという分析結果が得られるのはなぜか？グループ間の比較が母集団の何を推定しているか？
これはセレクションバイアルの分が本当の効果(100)に加算されているためである

注意：分析のバイアスがサンプルサイズが大きくなることによって解決されるという謎の議論が行われることがある


#### RCTが最も信頼のおける分析方法である理由
RCTが割り当てをランダムに行う。つまりは$Z_{i}$がランダムに決定されるので、潜在的な傾向が偏りにくい
ただし、これはサンプルサイズが十分に大きくないといけない。サンプルサイズによってそのサンプルグループのセ潜在的傾向の平均が偏る確率が小さくなる。
つまりは潜在的な傾向の期待値は介入の有無のグループで同一になるため、セレクションバイアスが0になることが期待できる。

##### 十分大きいとはどれくらい大きいのか? -> 有意差を算出できる程度のデータサイズとはどれくらいかは物によるけどこれ自体の算出が必要

#### 有意差検定

- 中心極限定理：手元に得られたデータにおける平均の分布は元々のデータがどんな分布であれ正規分布で近似できる
- t検定：中心極限定理を元に、対象とする分布の平均値が他と異なるかどうかを推定する(ex 分布Aの平均値が0と異なるかどうか)


t検定のプロセス
- 1.標準誤差の算出
   - 標準誤差：大雑把に得られた推定結果が変動しそうな範囲を示す
- 2.効果の推定値と標準誤差を使ってt値を算出
   - t値：グループ間の平均の差を標準誤差で割ることで、標準誤差の何倍あるかを算出したもの
- 3.t値を使ってp値を算出
   - p値：得られた推定結果の効果が0であるにもかかわらず得られてしまう確率
- 4.p値を有意水準と比較する
   - 有意水準：経験的に設定した水準よりもp値よりも低い場合には「本来の期待値は0である状態」から得られた可能性は十分に低いと結論づける


#### ビジネスにおける因果推論の必要性
- RCTの実行にはコストがかかる
   - 分析の上では良いがビジネス上大きなコストになる実験である
   - 倫理的観点や信用リスクから現実として不可能
- セレクションバイアスは不可避
    - 実験担当が利得を高めようと選択した結果現れる
- ビジネスにおけるバイアスのループ
    - PDCAを回すごとにバイアスが堆積する


# 参考文献
- [期待値の性質](https://k-san.link/linearity-of-expectation/)
- [分散 avrien](https://ai-trend.jp/basic-study/basic/variance/)

</details>

## 2章：介入効果を測るための回帰分析

<details>
<summary>memo</summary>

#### 回帰分析
##### 単回帰分析：変数が一つ
目的変数<img src="https://latex.codecogs.com/gif.latex?Y" />と入力となる変数$X$を用いて、<img src="https://latex.codecogs.com/gif.latex?X" />と<img src="https://latex.codecogs.com/gif.latex?Y" />の関係性を分析する。
この時、関係性に線形性を仮定する。すると一次式(傾きと切片)で関係を表せる。
ここで<img src="https://latex.codecogs.com/gif.latex?u_{i}" />は誤差項。


<img src="https://latex.codecogs.com/gif.latex?Y_{i} = \beta_{0} + \beta_{1}X_{i}+u_{i}" />

<br>
<br>

<img src="https://latex.codecogs.com/gif.latex?\beta_{0},\beta_{1}" />は真の値であるがこれはわからない。そこで手持ちのデータで得られる傾きと切片をそれぞれハットをつけて表し、これらを求めることとする。


<img src="https://latex.codecogs.com/gif.latex?\hat{\beta_{0}},&space;\hat{\beta_{1}}&space;=&space;\arg&space;min_{\beta_{0},&space;\beta_{1}}&space;\sum_{i=1}^{N}&space;(Y_{i}&space;-&space;\beta_{0}&space;-&space;\beta_{1}X_{i})^{2}" />

<br>
<br>

上記は最小二乗法と呼ばれ、傾き・切片に関してそれぞれ微分することで極値を求めることができ、最適なパラメータの推定ができる。

推定は母集団上での回帰分析で得られるパラメータに対して行われている。

##### 効果分析のための回帰分析
介入の効果は施策を行った場合と行わなかった場合の結果の期待値の差分
<img src="https://latex.codecogs.com/gif.latex?\tau=E[Y^{(1)}] - E[Y^{(0)}]" />で表される。

効果分析のための回帰分析では以下の変数を用いる。
- 被説明変数(Y：dependent variable) 介入による効果を確認したい変数
- 説明変数　効果に影響する変数
    - 介入変数(Z：treatment variable)　施策の有無を表す変数
    - 共変量(X：controle variable) 介入・施策の有無で傾向が異なっていると想定される変数


共変量は複数である場合が多く。このように説明変数が複数ある回帰分析を重回帰分析という。
推定したいものはZ、Xを与えられた時のYの期待値であるので

<img src="https://latex.codecogs.com/gif.latex?E[Y|X,Z] = \beta_{0} + \beta_{1}X+\beta_{2}Z" />

重回帰分析も条件付き期待値と回帰分析の関係性が成立


<img src="https://latex.codecogs.com/gif.latex?Y = E[Y|X,Z] + u = \beta_{0} + \beta_{1}X+\beta_{2}Z + u" />

この時誤差項の条件付き期待値<img src="https://latex.codecogs.com/gif.latex?E[u|X,Z]=0" />であり、uとX及びZは相関しないという性質を持つ.
重回帰分析も単回帰分析と同じく、二乗誤差の最小化問題としてとく・

##### 回帰分析による効果の推定
- 介入結果の差分が効果の期待値 -> 施策の係数<img src="https://latex.codecogs.com/gif.latex?\beta_{3}" />


##### 回帰分析における有意差検定

- 推定値<img src="https://latex.codecogs.com/gif.latex?\hat{\beta_{3}}" />が母集団上の<img src="https://latex.codecogs.com/gif.latex?\beta_{3}" />が0である可能性
- を研修する->有意差検定

##### 効果検証のための回帰分析で行わないこと

- <img src="https://latex.codecogs.com/gif.latex?\beta_{treatment}" />が興味のある値->介入変数の係数
- 介入変数の係数以外の情報は無視する-> 分析の目的から逸れるから

#### 回帰分析におけるバイアス
##### 共変量の追加による効果への作用
- 共変量とセレクションバイアスの関係性
- セレクションバイアスが発生しているデータに置いて、共変量を加えて回帰分析を行うことで影響を低減できる

##### 脱落変数バイアス(OVB)
- 共変量の追加でセレクションバイアスの影響を低減 -> 「どのような共変量をモデルに追加するべきか？」 -> 「目的変数Yと介入変数Zに対して相関のある変数を加えるべき」
- 追加することによってセレクションバイアスの影響の小さい結果を得られる共変量だがモデルから抜け落ちている変数 -> 脱落変数
- 必要な共変量がモデルに含まれない場合、推定される効果にはO脱落変数バイアス(OVB)が含まれる
- 有意差検定の結果で介入変数以外の結果を考慮しようとするとOVBを発生させる可能性がある


##### OVBが与えてくれる情報
- OVBの式は共変量が不十分なモデルの持つバイアスの構造を表す
- 構造とは、バイアスの値 = 「脱落変数とZの関係」　× 「脱落変数と目的変数の関係」
- これよりモデルに加えるべき共変量はZとYに相関するような変数 -> **交絡因子**

##### Conditional Independence Assumption（CIA）
- 共変量の選択の理想：モデルに含まれていない変数によるOVBが全て0になる
- モデルに含めた共変量で条件付けた時に、介入変数が<img src="https://latex.codecogs.com/gif.latex?Y^{(1)}" />や<img src="https://latex.codecogs.com/gif.latex?Y^{(1)}" />と独立している状態になる -> CIA
- 解釈としてじゃ共変量が同一のサンプルにおいて、介入Zはランダムに割り振られているのと同じになる
    - 年齢、性別、過去の購買額が同じ値のユーザーに施策を割り振る時、割り振りかたはサイコロを振るのと同じになる -> 割り振る人のバイアスがなくなる？


##### 変数の選び方とモデルの評価
問題
- バイアスの評価ができない -> 得られた効果の推定値がどの程度バイアスを含むか評価不能。OVBは相対的な数値なのでバイアスの大きさは示さない。
- 必要な共変量がデータにはない

上記二つの問題点は明確な指標を見ながらモデルの選択ができす、モデルの限界についても定量的に評価できないことを意味する。
これについては分析者の経験的な判断が求められる。またはより応用的な手法で対応する。

##### Sensitivity Analysis
- 回帰分析はセレクションバイアスを起こす変数をモデルに組み込むことで、その問題を軽減する方法
- データに含まれない変数がセレクションバイアスを起こす場合に対応不可能 -> 低減に使得ないから
- データに含まれない変数がセレクションバイアスを起こしているかは評価できる -> Sensitivity Analysis

Sensitivity Analisysとは、重要だと分析者が認識している共変量以外の共変量をモデルから除外することで、効果の推定値が大きく変動しないか確認するという分析です。

##### Post treatment bias
- セレクションバイアスが減る可能性がある、OVBの値が0でない変数を全てモデルに入れていいわけではない
- 因果的に介入の影響を受けた変数を分析にいれることによって起きるバイアス -> Post Treatment Bias
    - 例）サイト来訪者数の比較　メールを配信したグループ(元々サイト来訪するユーザ、メールが来たからサイト来訪したユーザ)　> メールが配信されなかったグループ（元々サイト来訪するユーザ）
    - 上の例でグループの売り上げ平均を見ると、明らかに配信されなかったグループが低くなる
- 介入よりもあとのタイミングで値が決まるような変数は分析から除外する


#### 回帰分析を利用した探索的な効果検証
Angrist et al(2002)はコロンビアで行われた私立学校の学費の割引に関する実験を分析した研究である。

##### PACESによろう学費の割引券配布の概要
- 教育に対する補助のあり方に関する議論
- 教育の提供側である学校に補助するか、受給側である生徒に補助するか
- 学費の半額を政府が肩代わりするという介入
- RCTではなく回帰分析 -> 調査の回答を得られる可能性が介入の有無によって変動するから

##### 乳立学校への通学と割引券の利用についての分析
- 当選グループにおいて私立学校で6年生を始める比率が6%高まった -> 当落に関係なく私立学校へ通う生徒が多い
-  そうせんグループにおいて何かしらの奨学金を調査期間中に使っている割合が非当選グループより高い

#### 回帰分析に関する様々な議論
##### 予測と効果推定
- モデルのデータに対する説明能力や未知のサンプルに対する予測能力を高めることが”効果検証において有用である”という保証にはならない

##### 制限被説明変数（Limited Dependent Variable）
- 予測や説明力を重視するようなモデルを扱う分野において、Yの分布に対してより適したモデルを選択されやすい
    - Yが購入したか否かのような二値 -> ロジスティック回帰
    - Yが売り上げのような0以上の整数値 -> ポアソン回帰
- 制限被説明変数：目的変数が特定の値しか撮らないような制約がある状態の変数
- 本書では介入変数が二値で線形回帰が行えるが、例えばZとYの関係が非線形であるなどしたら線形回帰の妥当性はない

##### 対数を利用した回帰分析
- 変数の自然対数をとった値をY、Xで利用することがある
- 目的変数の対数をとる場合の解釈 -> 推定されるパラメータはYに対して何%の影響があったか？
- 説明変数の対数をとる場合の解釈 -> 推定されたパラメータはXを1%変化させた時にYに対してどの程度の影響を与えるか？
- 使い所
    - 目的変数に対する介入の効果が比率で扱われるべきである場合
    - 共変量と目的変数の関係が比率で扱われるべきである場合

##### 多重共線性
- 多重共線性とは、回帰モデルに含まれている変数のうち二つが強い相関を持つ状況をさす。
- この場合、推定されるパラメータの標準誤差が変化してしまうため、検定の結果が歪む。
- 一番の問題は、推定されたおパラメータの標準誤差が信頼できない物になる点

</details>


## 3章：傾向スコアを用いた分析

<details>
<summary>memo</summary>


#### 傾向スコアの仕組み
##### 傾向スコアのアイデア

- 回帰分析は共変量の選定が重要
- しかし目的変数Yについての情報が十分に得られない場合がある
    - 目的変数に影響する変数が不明瞭 -> モデル化が難しい
    - 手元にあるデータが高次元（数千〜数万の変数）　-> 選定に時間がかかる 
- 傾向スコア：各サンプルにおいて介入が行われる確率
    - 着眼点：介入が行われた仕組みの解明
    - 目的：共変量の調整
    - 方法：介入グループと非介入グループの性質を均一にする操作を行う
- CIA（COnditional Independence Assumption）に近い
    - 共変量が同一のユーザの中では介入の決定はランダムに行われているに等しい
    - 傾向スコアが同一のユーザの(ry

傾向スコア<img src="https://latex.codecogs.com/gif.latex?P(X_{i})" />の仮定

<img src="https://latex.codecogs.com/gif.latex?{Y_{i}^{(1)}, Y_{i}^{(0)}} \perp Z|P(X_{i})" />

##### 傾向スコアの推定
- 傾向スコアを直接観測はできないが、結果であるZは観測可能
- 手持ちのデータから傾向スコアを推定する：ロジスティック回帰が多い
- ロジスティック回帰で得られた結果で重要なのは予測値
    - 推定されたパラメータの値が直感に息しているかの解釈は質の保証にならない
    - 傾向スコアの推定を行ったモデルに関しては特に解釈を行う必要はない

#### 傾向スコアを利用した効果の推定
##### 傾向スコアマッチング
介入変数Zの効果を推定する方法で今回紹介するのは以下二つ
- 傾向スコアマッチング：得られた傾向スコアを利用してサンプルどうしをマッチングさせる
- 逆確率重み付き推定：傾向スコアをサンプルの重みとして利用する

傾向スコアマッチングのアイデア
- 介入グループから取り出したサンプルの傾向スコアに近いものを、非介入グループからマッチングしてペアにする。
- ペアの中で目的変数の差を算出し、サンプルの数を重みとした重み付きの平均を推定値とする。
- ペアにする理由は傾向スコアが同じ物は介入がランダムに決定されているとみなせるから。
- つまりはセレクションバイアスの影響を受けない。

Average Treatment effect on Treated(ATT)
介入を受けたサンプルにおける介入効果の期待値

<img src="https://latex.codecogs.com/gif.latex?\hat{\tau}_{match} = E{E[Y|P(X), Z=1] - E[Y|P(X), Z=-} | Z=1}" />

<br>
<br>

問題点
- 計算時間が長い
- 変数が多くなると、傾向スコアが”同じ”という物は減っていくので”同じ”の判定方法を考える必要がある


##### 逆確率重み月推定
IPWのアイデア
- 傾向スコアをサンプルの重みとして利用して、与えられたデータ全体での介入の結果の期待値と非介入の結果の期待値の差分をとることで効果を推定
- IPWのセレクションバイアス：$P(X)$の偏りによって介入グループ自体に偏りが生じる
- 仮定：傾向スコアと介入の結果に正の相関がある -> この過程の妥当性は？
- この場合、$Y~{(1)}$が小さいデータほどZ-1のデータには含まれない -> 期待値が過剰に評価されて、推定される効果も過剰になる

IPWでは介入の結果の平均を次のように考える


<img src="https://latex.codecogs.com/gif.latex?\bar{Y^{(1)}} = \sum_{i=1}^{N} \frac{Z_{i}Y_{i}}{\hat{P(X_{i})}} / \frac{Z_{i}}{\hat{P(X_{i})}}" />


傾向スコアが大きくなるほど、傾向スコアの逆数が大きくなるため、サンプルに含まれないぶん重みを増加する。

やっていることは縦軸に介入の結果、横軸に傾向スコアをおいた分布を母集団の分布に近づけようとしている。

非介入の結果の推定は確率に<img src="https://latex.codecogs.com/gif.latex?1-\hat{p(X_{i})}" />を使って行う。

<img src="https://latex.codecogs.com/gif.latex?\bar{Y^{(0)}} = \sum_{i=1}^{N} \frac{(1-Z_{i})Y_{i}}{1- \hat{P(X_{i})}} / \frac{(1- Z_{i})}{1- \hat{P(X_{i})}}" />

これらよりIPWを用いた効果の推定値は

<img src="https://latex.codecogs.com/gif.latex?\hat{\tau_{IPW}} = \bar{Y^{(1)}} - \bar{Y^{(0)}} " />

#### より良い傾向スコアとは
- 傾向スコアはデータに対する説明力が一定を超えることが重要だと解釈される
- これはc統計量のような指標が基準を上回ることが望ましい（c統計量：大雑把にいうとROC曲線の下側の面積 医療統計で使われ、c>0.8なら良い多分経験的)
- 近年、傾向スコアを用いてマッチングや重みづけしたあとのデータで、共変量のバランスが取れているかが重要というのが一般的
- 標準化平均差（Average Standardized  Avsolute Mean distance：ASAM）
    - 平均の差をその標準誤差で割った物
    - ASAMが0.1以下がバランスが取れていると考えられる

##### 傾向スコアと回帰分析の比較
介入の効果の分析において、共変量の影響を取り除く点で両者はほぼ同じ。そこでどちらを使うべきかの話になる。

回帰分析
- 取り組みやすい
- 目的変数と共変量の関係についてのモデリングが必要
- いれるべき共変量をもでrに設定できないとOVBの影響が生じる
- OVBの評価やSensitivity Analysisなどの分析上のツールがある

傾向スコア
- 目的変数に対するモデリングを行わなくて済む
- Zの決定方法に関する調査で有益な情報を得られる
- 計算時間がかかるために大量の分析を行うことに向いていない

Yの値がどんな仕組みで決定されるかの情報が豊富な場合-> 回帰分析 not -> 傾向スコア
 
 ###### マッチングとIPWの差
 マッチング、IPW、回帰分析の結果はまず一致しない -> 推定しているものが異なる
 
-  マッチング：ペアが作れるデータ、つまりZ-1となるようなサンプルにおける平均的な効果を推定
-  IPW：得られたデータ全てに対して期待値を推定するので、Zに関わらず、全てのデータでの平均的な効果を推定

ビジネスの結果が実験と近いものであることを示す必要がある場合、実験のサンプルがどのような物かは注意が必要
 
 
#### LaLondeデータセットの分析
RCTの結果が本来は最も信頼できる分析であるが、それができないような状況で、信頼できる分析結果をたいというんが因果推論のモチベーション。
-> RCTによる実験結果を因果推論の方法で再現できるのか？(LaLonde)

NSW：労働市場へ参加できないような人々にカウンセリングと)~19ヶ月の短期的な就労経験を与えることを就職を助ける試みで、希望者からランダムに選択した人に対して介入を行った。肝は非介入グループを削除し、実験の外で得られたCPSという調査データを代わりに挿入してデータセットを作成し、これを持ってRCTの分析結果を擬似的に獲得した。
これを使ってRCTの分析を起こないNSWの結果と比較を行った。

- 回帰分析：NSWの実験で得られた結果とは大きく異なった。
- 傾向スコアマッチング：NSWの結果に近い結果を推定できた。


注意点
自分が分析するデータがどのようなデータであり、推定したい効果がどのようなサンプルにおける効果なのかに十分に配慮しなければならない。これが守られなければ、どのモデルの結果がより信頼たりえるかを判断することが非常に難しい。

</details>


## 4章：差分の差法とCausalImpact

<details>
<summary>memo</summary>


### DID(差分の差法)
#### DIDが必要になる状況
回帰分析と傾向スコアの適用の前提として「介入グループと非介入グループの両方に同じような特徴を持つサンプルが含まれている」があります。しかし、実際に得られるデータセットは同質のサンプルが存在しないことがよくあります。
以下が例です。

- 特定の地域における政策や法律の変更
- 特定の地域で広告を出稿する
- 特定の地域で商品の価格を変更する

例えば、ある地域の全てのスーパーで商品Aを10%値引きした時、その地域で値引きしない店舗は存在しません。理想的には個人や店舗単位で値引きを実施するようなRCTが行いたいですが、これ自体のコストまた顧客イメージ的に実行は現実的ではありません。

そこで非介入グループを他の地域から持ってくる場合が考えられますが、後で確認するようにセレクションバイアスが発生することになります。であれば、次に考えるのは時間軸方向の差分、過去のデータとの比較です。しかしこれについても過去と現在の差分が介入の見である保証はありません。

DID(Difference In Difference：差分の差法)は介入が行われた地域における介入の前後のデータと他の地域の介入の前後のデータを利用することで上記の問題点を乗り越える手法です。

大まかには介入前後での差分と介入の有無での差分をそれぞれ算出し、さらに地域での差分をとるという二段階の差分をとる方法です。

DIDを使った以下のような事例があります。
- Card(1990)：ボートでマイアミに到着した移民が労働市場にどのような影響を与えるか
- Blake et al(2015)：eBayで検索連動型広告の効果はどの程度か

#### 集計による効果検証とその欠点

地域ごとに複数の時期のデータを入手した場合、単純な集計による効果検証がよく行われる。
- 1.介入を受けた地域と受けなかった地域で売り上げを比較する
    - 地域固有の効果が介入の効果に含まれてしまう
    - どんな地域の選び方をしても排除できない (店舗でも同じ)
- 2.同じ地域の価格変動前後の売り上げデータを比較する(前後比較)
    - 地域におけるセレクションバイアスはなくなる
    - タイミングのセレクションバイアスが存在する
    - 時期による自然な変化(トレンド)が含まれる
        - ハロウィンやバレンタインでお菓子の売り上げが増加
        - 年末年始で交通量が増加
        - 夏のため、おでんや肉まんなどの売り上げが減少
            - 夏にもおでんを売るのは秋口の気温差によって体感温度が下がり顧客が購入するから

#### DIDのアイデアを用いた集計分析
同じ時期の他の地域との相対比較や、同じ地域別の時点での前後比較においてもバイアスが生まれる場合、どのように分析を行えばいいか？

John Snow(19世紀頃)がコレラの感染源を探る中でこの課題に直面した。
彼はDIDの基礎となるアイデア（介入の受けるグループと受けないグループでそれぞれ前後比較を行い、その結果を比較する）で、コレラの感染源が空気にあるのか水源にあるのかを検証。

調査対象となった地域では、二社（Soythwark and Vauxhall社、Lambeth社）によって水が提供されており、そのうちL社は水源をより上流へと移していた。もしコレラの感染源が水源であれば、二社の提供地域でのコレラの死者数には差が生じるはずでず。実際にはL社によって提供を受けていた地域では死者数の減少が見られた。これによりコレラの感染源は水である説が有力になります。

このアイデアの前提には平行トレンド仮定（Common Trend Assumption）があります。
これは「非介入グループのデータの変化と、介入グループが仮に介入を受けていなかった場合の変化が一致するだろう」という仮定です。


#### 回帰分析を利用したDID
DIDは回帰分析のフレームワークに当てはめることが可能。
DIDで扱うデータは同一の対象から別の期間で得られた物で、DIDの分析自体はエリアの数や期間の長さをとくに限定しません。Johnのデータセットでは複数のエリアで1849年、1853年と2回のデータが取得されています。

#### DIDにおける標準語さ
通常の回帰分析では大まかには一つの観測対象から一つのデータが得られるという想定をしています。一方、DIDの分析は同一の対象からいくつかの期間において取得したデータを利用します。この場合。自己相関（auto-crrelation, serial correlation）と呼ばれる状態を持つデータを得る可能性があります。

- 自己相関：ある時点で取得された変数の値がその近辺の時間で取得される同じ変数の値と相関するような状態
    - 例：コンビニエンスストアにおける売り上げを毎日観測した場合、周辺環境は大きく変化しないため。観測した任意の日とその前後の日の売り上げは非常に似た状態になる。

このデータで回帰分析を行った場合、誤差項の値は同一店舗で同じような値になる。そして回帰分析のパラメータの標準誤差は誤差項の分散を利用するため、結果として標準誤差が過小に算出されます。よって有意差検定で有意な結果よりになる。

回帰分析で想定していないデータ構造に対して、回帰分析を強引に利用したために起きる問題です。

このような場合はクラスター標準誤差（clustered standard error：以下CSE）を使用して、パラメータの標準誤差を算出する方法があります。CSEでは、指定した観測対象ごと（ex. 店舗）に誤差を観測していると考えて誤差項を扱います。


#### 平行トレンド仮定(Common Trend Assumption)と共変量
これまでの分析は、もしL社が水源を変更しなかった場合に、L社のみが提供する地域とL社及びSV社の両方　が提供する地域で、同様に死者数が増加すると行った仮定をおく。

このように、介入グループと非介入グループの目的変数の時間変化（トレンド）が同一であるという仮定を平行トレンド仮定という。DIDの根底のアイデアです。

これも実際には介入の有無でのデータで比較をし、仮定を満たすか確認したいが現実にはできません。もし介入までの期間がある程度長いデータを分析している場合、介入までのデータでトレンドが似ているかで仮定が満たされているか確認できます。しかし、この方法でも明確な傾向を得る事は多くの場合でできず、実際にはこれを適用する判断は分析者の分析対象への理解と解釈に依存します。

トレンドが同一でない場合、二つの対策をとることが可能です。
- 1.仮定を満たさないと考えられるデータを取り除く
    - 介入が行われた地域の近隣の地域を選択しないようにする
    - 介入のタイミングより前のデータを使って、トレンドが同一になるようなサンプルを自動的に検出する合成コントロールという方法もある
- 2.共変量としてトレンドの乖離を説明する変数をモデルに加える
    - コレラのデータでは、水源の変化以外に対象地域に衛生施設が建設されると仮定を満たさなくなる
    - 衛生施設付近では死者数が減るため、推定結果である死者数はOVBによって過少になると想定される


### CausalImpact
CausalImpactで用いられているBayesian Structureal Time Series Modelは扱う範囲を超えるため、基本的な考え方と使い方にフォーカスする。

#### DIDの欠点
1. 効果の影響を調べたい変数が複数の場所や時期で得られる必要がある.
2. どのデータを分析に用いるのかが分析社の仮説に依存する
    - 平行トレンド仮定により介入・非介入にかかわらず時間変化が本来は同質である必要がある

#### CausalImpactのアイデア
CausalImpactは複数の期間におけるデータを必要とする一方で、DIDの欠点を補うことができる分析方法です。DIDのアイデアは大まかには「介入が行われたサンプルの介入が行われなかった場合の結果を非介入グループのデータで補う」物です。反実仮想の結果を得られるなら（予測できるなら）、どのようなデータから予測しても良いのです。

CausalImpactは様々な変数Xを利用し、目的変数Yを予測できるようなモデルを介入が行われる前の期間のみで作成します。これによって介入後の目的変数Yを予測し、介入の結果と比較することで効果が得られます。

これも平行トレンド仮定が重要です。Xも介入の影響を受けるような変数の場合は取得するデータが影響を受けるということなので予測モデルの役割が満たせないことになります。

### 不完全な実験を補佐する
DIDやCausalImpactによる分析は実験が地理的、時間的に限定されている環境において有用な検証方法です。

しかし、効果を分析したい介入が他の介入や施策と同時に導入される場合、その効果を分析する事はできません。しかも、個別に分析するような事はほぼ不可能です。広告ではこのように複数の介入を行うことが多く、タイミング重なりが生むバイアスはマーケターの間ではアクティビティバイアスと呼ばれています。

</details>


## 5章：回帰不連続デザイン（RDD）

<details>
<summary>memo</summary>


### ルールが生み出すセレクションバイアス
介入の割り当てがルールベースの場合、傾向スコアが意味をなさなくなる。
- 男性・30際以上に介入を行うルール
- 上記の傾向スコアは常に1、上記以外の傾向スコアは常に0となる

このような場合でも利用できる分析方法が**回帰不連続デザイン（Regression Discontinuity Desgin: RDD）**

#### 回帰不連続デザインの仕組み
メール配信で考える。
- ルール：昨年の売り上げ（history）が基準額Aよりも多い場合にのみメール配信を行う
- 介入はhistoryに依存する

このように介入を決定する変数をrunning variableとよび。介入の有無の閾値のことをカットオフ（cut off）と呼びます。繰り返しになりますが、この場合running variableは昨年の売り上げ、カットオフは基準額Aになります。

介入の有無がカットオフで決まるため、時系列による介入タイミングを考慮するDIDは適していないため利用できません。

回帰不連続デザインはこのような状況に追いても、カットオフ付近のデータに着目することで効果を検証できる手法です。カットオフ近辺のデータでは過去の購買量は介入・非介入にかかわらず似通っており、同質のユーザが集まっているだろう -> 比較に追いてバイアスが小さいはずというアイデア。

#### 集計によるセレクションバイアスの確認
データの構造が持つ問題を整理する。
介入・非介入ぞれぞれで平均を算出して差分を効果とする単純な分析を行うとする。
ここで介入はrunning variableに置き換えられるので介入の効果<img src="https://latex.codecogs.com/gif.latex?\tau_{naive}">は次のように表せる。

<img src=
"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%5Cbegin%7Balign%2A%7D%0A%5Ctau_%7Bnaive%7D+%26%3D+E%5BY%5E%7B%281%29%7D%7CZ%3D1%5D+-+E%5BY%5E%7B%280%29%7D%7CZ%3D0%5D%5C%5C%0A%26%3D%5Ctau+%2B+E%5BY%5E%7B%280%29%7D%7CZ%3D1%5D+-+E%5BY%5E%7B%280%29%7D%7CZ%3D0%5D+%5C%5C%0A%26%3D%5Ctau+%2B+E%5BY%5E%7B%280%29%7D%7Chistory+%5Cgeq+A%5D+-+E%5BY%5E%7B%280%29%7D%7Chistory+%5Cleq+A%5D%0A%5Cend%7Balign%2A%7D" 
alt="\begin{align*}
\tau_{naive} &= E[Y^{(1)}|Z=1] - E[Y^{(0)}|Z=0]\\
&=\tau + E[Y^{(0)}|Z=1] - E[Y^{(0)}|Z=0] \\
&=\tau + E[Y^{(0)}|history \geq A] - E[Y^{(0)}|history \leq A]
\end{align*}">

このように本来知りたい効果に購買量のセレクションバイアスがついてきます。この大きさの分だけ効果が過剰に評価されます。

### 回帰不連続デザイン（RDD）
これまでと同じようにセレクションバイアスをどのようにして小さくするかが課題です。
介入がルールによって決定される場合。データの持つバイアスはrunning variableに依存するので、この場合historyがセレクションバイアスの原因です。よって、historyをどうやってコントロールするかが重要になります。

#### 線形回帰による分析
セレクションバイアスへの対応として真っ先に候補になるのは、線形回帰です。
これを考えるために、実験について次のように仮定をおきます。
- 介入目的：メールの配信でサイトの来訪者数を増やす
- 推定対象：メールの配信がサイト来訪者数をどの程度増やす効果があるのか
- 仮定1：running variableのhistoryがサイト来訪者数に対して線形の関係を持つ
- 仮定2:効果はhistoryの値に依存しない

よって、母集団上で次のような関係性があると仮定しています。

<img src=
"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%5Cbegin%7Balign%2A%7D%0AE%5BY%5E%7B%280%29%7D%7CX%5D+%26%3D+%5Cbeta_%7B0%7D+%2B+%5Cbeta_%7B1%7D+hisotry+%5C%5C%0AY%5E%7B%281%29%7D+%26%3D+Y%5E%7B%280%29%7D+%2B+%5Ctau%0A%5Cend%7Balign%2A%7D" 
alt="\begin{align*}
E[Y^{(0)}|X] &= \beta_{0} + \beta_{1} hisotry \\
Y^{(1)} &= Y^{(0)} + \tau
\end{align*}">

このとき、以下のように回帰分析を行うことで、推定結果τを得られます。

<img src=
"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%5Cbegin%7Balign%2A%7D%0AY+%3D+%5Cbeta_%7B0%7D+%2B+%5Cbeta_%7B1%7D+history+%2B+%5Crho+Z+%2B+u%0A%5Cend%7Balign%2A%7D" 
alt="\begin{align*}
Y = \beta_{0} + \beta_{1} history + \rho Z + u
\end{align*}">

この場合、セレクションバイアスはhistoryのみによって生じるのでバイアスがなくなった結果を得ることができます。ただし、真琴の関係が非線形だった場合セレクションバイアスを適切に除去できないことに注意してください。

#### 非線形回帰による分析
もしhistoryとYの関係性が非線形であれば、非線形性を考慮した共変量をモデルに含める必要があります。この場合の最も単純な回帰分析は次のようにXの一乗からp乗までをモデルに含むような冪乗のモデルになります。また注意点として、適切に共変量が含まれていない場合、OVBが発生することになります。

<img src=
"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%5Cbegin%7Balign%2A%7D%0AY+%3D+%5Cbeta_%7B0%7D+%2B+%5Cbeta_%7B1%7DX+%5Ccdots+%5Cbeta_%7Bp%7DX%5E%7Bp%7D+%2B+%5Crho+Z+%2B+u%0A%5Cend%7Balign%2A%7D" 
alt="\begin{align*}
Y = \beta_{0} + \beta_{1}X \cdots \beta_{p}X^{p} + \rho Z + u
\end{align*}">

### nonparametric RDD
#### nonparametric RDDの仕組み
running variableと目的変数の関係が非線形の場合に利用できる分析手法-> **nonparametric RDD**

利用するデータを閾値の前後に限定することでセレクションバイアスを小さくするアイデアです。

ただし、範囲を限定するほどバイアスが小さくなりますが、サンプルサイズが小さくなるために標準誤差が大きくなるというトレードオフの関係が存在します。


### 回帰不連続デザインの仮定
DIDは平行トレンド仮定を前提とするように、RDDにも前提とする仮定があります。ここではそれを確認します。

#### Continuity of Conditional Regression Functions
RDDで推定された結果が正しいと考えるためにContinuity of Conditional Regression Functionsを満たす必要があります。また、次のことを仮定しています。
- 介入を受けた場合と受けなかった場合における条件付き期待値が共変量に対して連続である
- 大まかには別の介入が存在しないこと

#### non-manipulation
- non-manipulation：分析の対象が自身の介入に関するステータスを調整できないという仮定

あるユーザーがカットオフについて知っており、来年クーポンを入手するために購入額を操作するとします。
これによりカットオフ付近のユーザー分布が大きく変化してしまいます。このような状況が発生しているか否かはカットオフ付近でのデータ量（密度）に着目して判別できます。

#### LATEの妥当性
回帰分析における介入の効果は主に「介入グループと非介入グループの割合がちょうど1対1になっているようなサンプル」を中心に算出されています。ルールによる割り振りの場合、カットオフ付近のデータが対象になります。よって、この場合の推定される効果はカットオフ付近の効果であり、**Local Average Treatment Effect(LATE)**といいます。

RDDで得られた効果がカットオフ付近のみでなく、データ全体における平均的な効果と考えるためには、介入の効果がrunning variableの値によっては変化しないという仮定が必要です。この仮定はデータからではわからないため、分析者のデータ解釈が仮定の妥当性を評価することになります。

### ビジネスにおける介入割り当てルール
RDDを紹介する理由は、介入の割り当てがルールによって設定されていることがビジネスにおいて非常に多いからです。統計モデルや機械学習を利用して施策の操作（決定論的なルールを用いての介入）が多いため。

#### ユーザーセグメントへの介入
マーケティング活動ではユーザを特定の属性ごとにまとめて扱うユーザーセグメントを用いることが多い。

ユーザーセグメントを作成する手順は大まかに二つ。
- ユーザの属性や特徴をルールベースで分ける
- 機械学習や統計モデルでユーザーごとに算出した予測値に閾値を設ける

#### Uberによる価格変更の分析
UberはRDDを使って経済学者と分析を行っていることで有名。
収益ドライバーは、特定の場所に移動したユーザとタクシーなどのドライバーのマッチング。
あるエリアでユーザ需要が増えるとドライバーの数が減少するため、運賃調整の仕組みを使って、価格上昇を行う。これによって周辺地域からドライバーの流入が図れる。

この時、エリアごとの需要予測に機械学習を使っている。予測値が閾値を超えると、価格上昇が生じ、この価格変化がユーザーとドライバーにもたらす影響をRDDで分析する。この時、需要の予測値が介入の有無に影響するのでrunning variableになる。

これに関する分析はいくつかある。
- Chen et al(2016) 価格増加により収益増のためにドライバーの労働時間が増加、ユーザの需要も満たせる
- Cohen et al(2016) それぞれの閾値で起きる価格変動が需要に与えた影響を推定することで需要曲線を実際に観測 -> 価格上昇に伴い乗車確率が低下

需要曲線とは、ミクロ経済学における概念。ある商品について、他の全ての条件が同一の場合には価格が上昇すると需要が低下するという関係性のこと。

</details>

